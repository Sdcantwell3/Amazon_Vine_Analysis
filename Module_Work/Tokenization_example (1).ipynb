{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hYt5VItdiupUpwiLVx2BUb2SDbSYMa5j","timestamp":1660699766389}],"collapsed_sections":[],"authorship_tag":"ABX9TyN6aVJxPs08Q3pTfp28dJw2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpo8SdL2KpUo","executionInfo":{"status":"ok","timestamp":1662425105149,"user_tz":360,"elapsed":23396,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}},"outputId":"f6dd3ae2-85b5-4fc0-cd87-c3d6a5d37a44"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Waiting for headers] [Wai\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.91.39)]\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.1.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"metadata":{"id":"pD8pS7aGQh5O","executionInfo":{"status":"ok","timestamp":1662425131973,"user_tz":360,"elapsed":8632,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer"],"metadata":{"id":"N1ADRgq2Qnee","executionInfo":{"status":"ok","timestamp":1662425142631,"user_tz":360,"elapsed":301,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Create sample DataFrame\n","dataframe = spark.createDataFrame([\n","    (0, \"Spark is Great\"),\n","    (1, \"We are learning Spark\"),\n","    (2, \"Spark is better than hadoop no doubt\")\n","],[\"id\", \"sentence\"])\n","\n","dataframe.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODpRxLcCQwR4","executionInfo":{"status":"ok","timestamp":1662425320787,"user_tz":360,"elapsed":6153,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}},"outputId":"ea5461f6-e1e3-4f05-cbfb-e23b425cd3cc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is Great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1xT7j4CRb96","executionInfo":{"status":"ok","timestamp":1662425460621,"user_tz":360,"elapsed":232,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}},"outputId":"6262651c-b250-4729-9e5d-8bf2b2b0e38b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_42efb9d85569"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#Transform ans show DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZOqYI2BR3oD","executionInfo":{"status":"ok","timestamp":1662425517256,"user_tz":360,"elapsed":1388,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}},"outputId":"2bbcaa1a-803c-4353-f68b-e4daf2317b02"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is Great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","  return len(word_list)"],"metadata":{"id":"jq316Iu0SPQv","executionInfo":{"status":"ok","timestamp":1662425617946,"user_tz":360,"elapsed":134,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"metadata":{"id":"OMcB5qSPSh-2","executionInfo":{"status":"ok","timestamp":1662425672694,"user_tz":360,"elapsed":150,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Create a user defined function\n","\n","count_tokens = udf(word_list_length, IntegerType())"],"metadata":{"id":"ceZCx3A8Stds","executionInfo":{"status":"ok","timestamp":1662425738008,"user_tz":360,"elapsed":141,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#Create our Tokenizer\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","\n","#Transform DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","\n","# Select the needed columsn and don't truncate results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeM9ivmkTBjz","executionInfo":{"status":"ok","timestamp":1662425897725,"user_tz":360,"elapsed":991,"user":{"displayName":"Stephen Cantwell","userId":"07933034955480129716"}},"outputId":"daa2f682-bb97-45bf-acdd-cd679f47bc0c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is Great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]}]}